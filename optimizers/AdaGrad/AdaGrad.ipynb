{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150, 3)\n",
      "(120, 4) (30, 4) (120, 3) (30, 3)\n"
     ]
    }
   ],
   "source": [
    "x = iris.data\n",
    "\n",
    "label = iris.target\n",
    "\n",
    "y = np.zeros(label.shape + (3,))\n",
    "y[np.arange(label.shape[0]),label] = 1\n",
    "\n",
    "print x.shape, y.shape\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    x[x < 0] = 0\n",
    "    return x\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def deriv(x, activation = 'relu'):\n",
    "    if(activation == 'relu'):\n",
    "        x[x > 0] = 1\n",
    "        x[x < 0] = 0\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_initializer(fan_in,fan_out):\n",
    "    return np.random.normal(0,np.sqrt(2*1.0/(fan_in+fan_out)),(fan_out,fan_in+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Output shapes of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(feed_dict):\n",
    "    feed_dict['input_shape'] = feed_dict['train_input'].shape[1:]\n",
    "    inp_shape = feed_dict['input_shape']\n",
    "    feed_dict['output'] = []\n",
    "    layers = feed_dict['layers']\n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "        output_shape = (layers[i]['nodes'],1)\n",
    "        out_dict = {'layer_number': i , 'type': 'fc', 'output_shape': output_shape}\n",
    "        feed_dict['output'].append(out_dict)\n",
    "        inp_shape = output_shape\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(inp, weights,  nodes, activation):\n",
    "    inp = np.asarray(inp).reshape(len(inp),1)\n",
    "    inp = np.vstack((np.array(inp),1))\n",
    "    #initiazing weights\n",
    "#     weights = np.asmatrix(np.random.rand(nodes, len(inp)))\n",
    "    output_raw = np.matmul(weights, inp)\n",
    "    #normalizing the output to ensure no overflow in exp\n",
    "#     print np.max(output_raw)\n",
    "    output_raw = output_raw \n",
    "    #applying activation function\n",
    "    if(activation == 'sigmoid'):\n",
    "        output = sigmoid(output_raw)\n",
    "    elif(activation == 'relu'):\n",
    "        output = relu(output_raw)\n",
    "    elif(activation == 'tanh'):\n",
    "        output = tanh(output_raw)\n",
    "    elif(activation == 'softmax'):\n",
    "        output = softmax(output_raw)\n",
    "    else:\n",
    "        output = output_raw\n",
    "    #making the output vector as column matrix\n",
    "    if(output.shape[0] == 1):\n",
    "        output = np.moveaxis(output, 0,1)\n",
    "        output_raw = np.moveaxis(output_raw, 0,1)\n",
    "    return output, output_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {}\n",
    "feed_dict['train_input'] = x_train\n",
    "feed_dict['train_label'] = y_train\n",
    "feed_dict['test_input'] = x_test\n",
    "feed_dict['test_label'] = y_test\n",
    "feed_dict['const_delta'] = 1e-9\n",
    "feed_dict['learning_rate_epsilon'] = 1e-2\n",
    "feed_dict['epochs'] = 2000\n",
    "feed_dict['batch_size'] = 5\n",
    "feed_dict['layers'] = [{'type': 'fc',  'nodes': 10, 'activation' : 'relu'},\n",
    "                       {'type': 'fc',  'nodes': 10, 'activation' : 'relu'},\n",
    "                       {'type': 'fc',  'nodes': 3, 'activation' : 'softmax'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the outputs and initializng the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shapes:\n",
      "fc0 :  (10, 1)\n",
      "fc1 :  (10, 1)\n",
      "fc2 :  (3, 1)\n",
      "\n",
      "\n",
      "weight matrices shapes (with biases):\n",
      "fc0 (10, 5)\n",
      "fc1 (10, 11)\n",
      "fc2 (3, 11)\n"
     ]
    }
   ],
   "source": [
    "feed_dict = get_model(feed_dict)\n",
    "\n",
    "print 'output shapes:'\n",
    "for i in range(len(feed_dict['layers'])):\n",
    "    print feed_dict['layers'][i]['type']+str(i) , ': ', feed_dict['output'][i]['output_shape']\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "feed_dict['output'][0]['weights'] = xavier_initializer(feed_dict['input_shape'][0], feed_dict['layers'][0]['nodes'])\n",
    "feed_dict['output'][1]['weights'] = xavier_initializer(feed_dict['output'][0]['output_shape'][0], feed_dict['layers'][1]['nodes'])\n",
    "feed_dict['output'][2]['weights'] = xavier_initializer(feed_dict['output'][1]['output_shape'][0], feed_dict['layers'][2]['nodes'])\n",
    "\n",
    "print 'weight matrices shapes (with biases):'\n",
    "print feed_dict['layers'][0]['type']+str(0),feed_dict['output'][0]['weights'].shape\n",
    "print feed_dict['layers'][1]['type']+str(1),feed_dict['output'][1]['weights'].shape\n",
    "print feed_dict['layers'][2]['type']+str(2),feed_dict['output'][2]['weights'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = feed_dict['epochs']\n",
    "no_samples = len(x_train)\n",
    "batch_size = feed_dict['batch_size']\n",
    "no_batches = no_samples/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 6)\n"
     ]
    }
   ],
   "source": [
    "tpp = [np.random.rand(3,3), np.random.rand(4,5,6), np.random.rand(5,8,7,6,5)]\n",
    "print tpp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 Loss: [0.29715023]\n",
      "Epoch: 100 Loss: [0.21061697]\n",
      "Epoch: 150 Loss: [0.16604365]\n",
      "Epoch: 200 Loss: [0.14082759]\n",
      "Epoch: 250 Loss: [0.12373317]\n",
      "Epoch: 300 Loss: [0.11193395]\n",
      "Epoch: 350 Loss: [0.10318543]\n",
      "Epoch: 400 Loss: [0.0972053]\n",
      "Epoch: 450 Loss: [0.09170451]\n",
      "Epoch: 500 Loss: [0.08767076]\n",
      "Epoch: 550 Loss: [0.08440788]\n",
      "Epoch: 600 Loss: [0.08149092]\n",
      "Epoch: 650 Loss: [0.07945476]\n",
      "Epoch: 700 Loss: [0.07734208]\n",
      "Epoch: 750 Loss: [0.075596]\n",
      "Epoch: 800 Loss: [0.07348305]\n",
      "Epoch: 850 Loss: [0.07224495]\n",
      "Epoch: 900 Loss: [0.07059036]\n",
      "Epoch: 950 Loss: [0.07007791]\n",
      "Epoch: 1000 Loss: [0.06875975]\n",
      "Epoch: 1050 Loss: [0.06725993]\n",
      "Epoch: 1100 Loss: [0.0666131]\n",
      "Epoch: 1150 Loss: [0.06559599]\n",
      "Epoch: 1200 Loss: [0.06495209]\n",
      "Epoch: 1250 Loss: [0.06411008]\n",
      "Epoch: 1300 Loss: [0.06392253]\n",
      "Epoch: 1350 Loss: [0.06299444]\n",
      "Epoch: 1400 Loss: [0.06237286]\n",
      "Epoch: 1450 Loss: [0.06208758]\n",
      "Epoch: 1500 Loss: [0.06155842]\n",
      "Epoch: 1550 Loss: [0.06108415]\n",
      "Epoch: 1600 Loss: [0.06053189]\n",
      "Epoch: 1650 Loss: [0.06033114]\n",
      "Epoch: 1700 Loss: [0.05993671]\n",
      "Epoch: 1750 Loss: [0.05977705]\n",
      "Epoch: 1800 Loss: [0.05946105]\n",
      "Epoch: 1850 Loss: [0.05880969]\n",
      "Epoch: 1900 Loss: [0.05851433]\n",
      "Epoch: 1950 Loss: [0.05806288]\n",
      "Epoch: 2000 Loss: [0.05792227]\n"
     ]
    }
   ],
   "source": [
    "layers = feed_dict['layers']\n",
    "train_losses = []\n",
    "feed_dict['rr'] = [np.zeros(feed_dict['output'][0]['weights'].shape), np.zeros(feed_dict['output'][1]['weights'].shape), np.zeros(feed_dict['output'][2]['weights'].shape)]\n",
    "for epoch in range(epochs):\n",
    "    cost_per_epoch = 0\n",
    "    #shuffling the data\n",
    "    s = np.arange(feed_dict['train_input'].shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    feed_dict['train_input'] = feed_dict['train_input'][s]\n",
    "    feed_dict['train_label'] = feed_dict['train_label'][s]\n",
    "    for batch in range(no_batches):\n",
    "        # weight matrices for sum of updates of batch\n",
    "        weights_fc_0 = np.zeros(feed_dict['output'][0]['weights'].shape)\n",
    "        weights_fc_1 = np.zeros(feed_dict['output'][1]['weights'].shape)\n",
    "        weights_fc_2 = np.zeros(feed_dict['output'][2]['weights'].shape)\n",
    "        for i in range(batch_size):\n",
    "            #feeding forward\n",
    "            feed_dict['output'][0]['output'], feed_dict['output'][0]['output_raw'] = fully_connected(feed_dict['train_input'][i + batch * batch_size], weights = feed_dict['output'][0]['weights'], nodes = layers[0]['nodes'], activation = layers[0]['activation'])\n",
    "            feed_dict['output'][1]['output'], feed_dict['output'][1]['output_raw'] = fully_connected(feed_dict['output'][0]['output'], weights = feed_dict['output'][1]['weights'], nodes = layers[1]['nodes'], activation = layers[1]['activation'])\n",
    "            feed_dict['output'][2]['output'], feed_dict['output'][2]['output_raw'] = fully_connected(feed_dict['output'][1]['output'], weights = feed_dict['output'][2]['weights'], nodes = layers[2]['nodes'], activation = layers[2]['activation'])\n",
    "            \n",
    "            #cost calculation\n",
    "            cost_per_epoch = cost_per_epoch - np.log(feed_dict['output'][2]['output'][np.argmax(feed_dict['train_label'][i + batch * batch_size])])\n",
    "            \n",
    "            #calculating the gradients\n",
    "            feed_dict['output'][2]['semi_update'] = feed_dict['output'][2]['output'] - feed_dict['train_label'][i + batch * batch_size].reshape(-1,1)\n",
    "            feed_dict['output'][2]['update'] = np.matmul(feed_dict['output'][2]['semi_update'] , np.transpose(np.vstack((feed_dict['output'][1]['output'],1))))\n",
    "            \n",
    "            temp = feed_dict['output'][2]['weights'][:,0:feed_dict['output'][2]['weights'].shape[1]-1]\n",
    "            feed_dict['output'][1]['semi_update'] = np.matmul(np.transpose(temp), feed_dict['output'][2]['semi_update']) * deriv(feed_dict['output'][1]['output_raw'])\n",
    "            feed_dict['output'][1]['update'] = np.matmul(feed_dict['output'][1]['semi_update'] , np.transpose(np.vstack((feed_dict['output'][0]['output'],1))))\n",
    "            \n",
    "            temp = feed_dict['output'][1]['weights'][:,0:feed_dict['output'][1]['weights'].shape[1]-1]\n",
    "            feed_dict['output'][0]['semi_update'] = np.matmul(np.transpose(temp), feed_dict['output'][1]['semi_update']) * deriv(feed_dict['output'][0]['output_raw'])\n",
    "            feed_dict['output'][0]['update'] = np.matmul(feed_dict['output'][0]['semi_update'],np.transpose(np.vstack((np.expand_dims(feed_dict['train_input'][i + batch * batch_size],axis = 1),1))))\n",
    "            \n",
    "            weights_fc_0 += feed_dict['output'][0]['update']\n",
    "            weights_fc_1 += feed_dict['output'][1]['update']\n",
    "            weights_fc_2 += feed_dict['output'][2]['update']\n",
    "            \n",
    "        #updating the gradient after each batch\n",
    "        feed_dict['rr'][0] = feed_dict['rr'][0] + (weights_fc_0 * weights_fc_0)\n",
    "        feed_dict['rr'][1] = feed_dict['rr'][1] + (weights_fc_1 * weights_fc_1)\n",
    "        feed_dict['rr'][2] = feed_dict['rr'][2] + (weights_fc_2 * weights_fc_2) \n",
    "        feed_dict['output'][0]['weights'] -= (feed_dict['learning_rate_epsilon']*weights_fc_0)/(feed_dict['const_delta'] + np.sqrt(feed_dict['rr'][0]))\n",
    "        feed_dict['output'][1]['weights'] -= (feed_dict['learning_rate_epsilon']*weights_fc_1)/(feed_dict['const_delta'] + np.sqrt(feed_dict['rr'][1]))\n",
    "        feed_dict['output'][2]['weights'] -= (feed_dict['learning_rate_epsilon']*weights_fc_2)/(feed_dict['const_delta'] + np.sqrt(feed_dict['rr'][2]))\n",
    "        \n",
    "    #printing the Average Loss after each epoch\n",
    "    if((epoch+1)%50 ==0):\n",
    "        print(\"Epoch: \" + str(epoch+1) + \" Loss: \" + str(cost_per_epoch/no_samples))\n",
    "    train_losses.append(cost_per_epoch/no_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"adagrad.npy\", feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = np.array(train_losses)\n",
    "plt.plot(train_losses)\n",
    "plt.title('LOSS Vs Epochs')\n",
    "plt.ylabel('Cross Entrphoy Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of softmax for one sample:\n",
      "[[9.99982461e-01]\n",
      " [1.75390094e-05]\n",
      " [4.93348474e-13]]\n",
      "\n",
      "Ground Truth of the same sample above:\n",
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "feed_dict['output'][0]['output'], feed_dict['output'][0]['output_raw'] = fully_connected(feed_dict['train_input'][0], weights = feed_dict['output'][0]['weights'], nodes = layers[0]['nodes'], activation = layers[0]['activation'])\n",
    "feed_dict['output'][1]['output'], feed_dict['output'][1]['output_raw'] = fully_connected(feed_dict['output'][0]['output'], weights = feed_dict['output'][1]['weights'], nodes = layers[1]['nodes'], activation = layers[1]['activation'])\n",
    "feed_dict['output'][2]['output'], feed_dict['output'][2]['output_raw'] = fully_connected(feed_dict['output'][1]['output'], weights = feed_dict['output'][2]['weights'], nodes = layers[2]['nodes'], activation = layers[2]['activation'])\n",
    "\n",
    "print 'output of softmax for one sample:'\n",
    "print feed_dict['output'][2]['output']\n",
    "\n",
    "print '\\nGround Truth of the same sample above:'\n",
    "print feed_dict['train_label'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = []\n",
    "gt = []\n",
    "# print(np.argmax(out))\n",
    "for i in range(feed_dict['test_input'].shape[0]):\n",
    "    feed_dict['output'][0]['output'], feed_dict['output'][0]['output_raw'] = fully_connected(feed_dict['test_input'][i], weights = feed_dict['output'][0]['weights'], nodes = layers[0]['nodes'], activation = layers[0]['activation'])\n",
    "    feed_dict['output'][1]['output'], feed_dict['output'][1]['output_raw'] = fully_connected(feed_dict['output'][0]['output'], weights = feed_dict['output'][1]['weights'], nodes = layers[1]['nodes'], activation = layers[1]['activation'])\n",
    "    feed_dict['output'][2]['output'], feed_dict['output'][2]['output_raw'] = fully_connected(feed_dict['output'][1]['output'], weights = feed_dict['output'][2]['weights'], nodes = layers[2]['nodes'], activation = layers[2]['activation'])\n",
    "    \n",
    "    test_predicted.append(np.argmax(feed_dict['output'][2]['output']))\n",
    "    gt.append(np.argmax(feed_dict['test_label'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs and the respective Groucd Truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 0, 1, 0, 1, 1, 2, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 0, 0]\n",
      "Actual   :  [0, 0, 1, 0, 1, 1, 2, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print 'predicted: ',test_predicted\n",
    "print 'Actual   : ', gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array(test_predicted) - np.array(gt)\n",
    "test_accuracy = (len(a) - np.count_nonzero(a))/float(len(a))\n",
    "\n",
    "print 'accuracy: ', str(test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
