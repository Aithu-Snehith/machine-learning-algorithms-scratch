{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150, 3)\n",
      "(120, 4) (30, 4) (120, 3) (30, 3)\n"
     ]
    }
   ],
   "source": [
    "x = iris.data\n",
    "\n",
    "label = iris.target\n",
    "\n",
    "y = np.zeros(label.shape + (3,))\n",
    "y[np.arange(label.shape[0]),label] = 1\n",
    "\n",
    "print x.shape, y.shape\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    x[x < 0] = 0\n",
    "    return x\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def deriv(x, activation = 'relu'):\n",
    "    if(activation == 'relu'):\n",
    "        x[x > 0] = 1\n",
    "        x[x < 0] = 0\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_initializer(fan_in,fan_out):\n",
    "    return np.random.normal(0,np.sqrt(2*1.0/(fan_in+fan_out)),(fan_out,fan_in+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Output shapes of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(feed_dict):\n",
    "    feed_dict['input_shape'] = feed_dict['train_input'].shape[1:]\n",
    "    inp_shape = feed_dict['input_shape']\n",
    "    feed_dict['output'] = []\n",
    "    layers = feed_dict['layers']\n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "        output_shape = (layers[i]['nodes'],1)\n",
    "        out_dict = {'layer_number': i , 'type': 'fc', 'output_shape': output_shape}\n",
    "        feed_dict['output'].append(out_dict)\n",
    "        inp_shape = output_shape\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(inp, weights,  nodes, activation):\n",
    "    inp = np.asarray(inp).reshape(len(inp),1)\n",
    "    inp = np.vstack((np.array(inp),1))\n",
    "    #initiazing weights\n",
    "#     weights = np.asmatrix(np.random.rand(nodes, len(inp)))\n",
    "    output_raw = np.matmul(weights, inp)\n",
    "    #normalizing the output to ensure no overflow in exp\n",
    "#     print np.max(output_raw)\n",
    "    output_raw = output_raw \n",
    "    #applying activation function\n",
    "    if(activation == 'sigmoid'):\n",
    "        output = sigmoid(output_raw)\n",
    "    elif(activation == 'relu'):\n",
    "        output = relu(output_raw)\n",
    "    elif(activation == 'tanh'):\n",
    "        output = tanh(output_raw)\n",
    "    elif(activation == 'softmax'):\n",
    "        output = softmax(output_raw)\n",
    "    else:\n",
    "        output = output_raw\n",
    "    #making the output vector as column matrix\n",
    "    if(output.shape[0] == 1):\n",
    "        output = np.moveaxis(output, 0,1)\n",
    "        output_raw = np.moveaxis(output_raw, 0,1)\n",
    "    return output, output_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {}\n",
    "feed_dict['train_input'] = x_train\n",
    "feed_dict['train_label'] = y_train\n",
    "feed_dict['test_input'] = x_test\n",
    "feed_dict['test_label'] = y_test\n",
    "feed_dict['learning_rate_alpha'] = 0.2\n",
    "feed_dict['learning_rate_epsilon'] = 1e-3\n",
    "feed_dict['epochs'] = 1000\n",
    "feed_dict['batch_size'] = 5\n",
    "feed_dict['layers'] = [{'type': 'fc',  'nodes': 10, 'activation' : 'relu'},\n",
    "                       {'type': 'fc',  'nodes': 10, 'activation' : 'relu'},\n",
    "                       {'type': 'fc',  'nodes': 3, 'activation' : 'softmax'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the outputs and initializng the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shapes:\n",
      "fc0 :  (10, 1)\n",
      "fc1 :  (10, 1)\n",
      "fc2 :  (3, 1)\n",
      "\n",
      "\n",
      "weight matrices shapes (with biases):\n",
      "fc0 (10, 5)\n",
      "fc1 (10, 11)\n",
      "fc2 (3, 11)\n"
     ]
    }
   ],
   "source": [
    "feed_dict = get_model(feed_dict)\n",
    "\n",
    "print 'output shapes:'\n",
    "for i in range(len(feed_dict['layers'])):\n",
    "    print feed_dict['layers'][i]['type']+str(i) , ': ', feed_dict['output'][i]['output_shape']\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "feed_dict['output'][0]['weights'] = xavier_initializer(feed_dict['input_shape'][0], feed_dict['layers'][0]['nodes'])\n",
    "feed_dict['output'][1]['weights'] = xavier_initializer(feed_dict['output'][0]['output_shape'][0], feed_dict['layers'][1]['nodes'])\n",
    "feed_dict['output'][2]['weights'] = xavier_initializer(feed_dict['output'][1]['output_shape'][0], feed_dict['layers'][2]['nodes'])\n",
    "\n",
    "print 'weight matrices shapes (with biases):'\n",
    "print feed_dict['layers'][0]['type']+str(0),feed_dict['output'][0]['weights'].shape\n",
    "print feed_dict['layers'][1]['type']+str(1),feed_dict['output'][1]['weights'].shape\n",
    "print feed_dict['layers'][2]['type']+str(2),feed_dict['output'][2]['weights'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = feed_dict['epochs']\n",
    "no_samples = len(x_train)\n",
    "batch_size = feed_dict['batch_size']\n",
    "no_batches = no_samples/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 6)\n"
     ]
    }
   ],
   "source": [
    "tpp = [np.random.rand(3,3), np.random.rand(4,5,6), np.random.rand(5,8,7,6,5)]\n",
    "print tpp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 Loss: [0.12150044]\n",
      "Epoch: 100 Loss: [0.09218817]\n",
      "Epoch: 150 Loss: [0.08350655]\n",
      "Epoch: 200 Loss: [0.09055127]\n",
      "Epoch: 250 Loss: [0.07398443]\n",
      "Epoch: 300 Loss: [0.08840344]\n",
      "Epoch: 350 Loss: [0.07382845]\n",
      "Epoch: 400 Loss: [0.06529177]\n",
      "Epoch: 450 Loss: [0.07873084]\n",
      "Epoch: 500 Loss: [0.07140534]\n",
      "Epoch: 550 Loss: [0.06739442]\n",
      "Epoch: 600 Loss: [0.07533091]\n",
      "Epoch: 650 Loss: [0.07226063]\n",
      "Epoch: 700 Loss: [0.05380276]\n",
      "Epoch: 750 Loss: [0.07500372]\n",
      "Epoch: 800 Loss: [0.08401277]\n",
      "Epoch: 850 Loss: [0.07032913]\n",
      "Epoch: 900 Loss: [0.06228299]\n",
      "Epoch: 950 Loss: [0.06785453]\n",
      "Epoch: 1000 Loss: [0.06775032]\n"
     ]
    }
   ],
   "source": [
    "layers = feed_dict['layers']\n",
    "train_losses = []\n",
    "feed_dict['vel'] = [np.zeros(feed_dict['output'][0]['weights'].shape), np.zeros(feed_dict['output'][1]['weights'].shape), np.zeros(feed_dict['output'][2]['weights'].shape)]\n",
    "for epoch in range(epochs):\n",
    "    cost_per_epoch = 0\n",
    "    #shuffling the data\n",
    "    s = np.arange(feed_dict['train_input'].shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    feed_dict['train_input'] = feed_dict['train_input'][s]\n",
    "    feed_dict['train_label'] = feed_dict['train_label'][s]\n",
    "    for batch in range(no_batches):\n",
    "        # weight matrices for sum of updates of batch\n",
    "        weights_fc_0 = np.zeros(feed_dict['output'][0]['weights'].shape)\n",
    "        weights_fc_1 = np.zeros(feed_dict['output'][1]['weights'].shape)\n",
    "        weights_fc_2 = np.zeros(feed_dict['output'][2]['weights'].shape)\n",
    "        for i in range(batch_size):\n",
    "            #feeding forward\n",
    "            feed_dict['output'][0]['output'], feed_dict['output'][0]['output_raw'] = fully_connected(feed_dict['train_input'][i + batch * batch_size], weights = feed_dict['output'][0]['weights'], nodes = layers[0]['nodes'], activation = layers[0]['activation'])\n",
    "            feed_dict['output'][1]['output'], feed_dict['output'][1]['output_raw'] = fully_connected(feed_dict['output'][0]['output'], weights = feed_dict['output'][1]['weights'], nodes = layers[1]['nodes'], activation = layers[1]['activation'])\n",
    "            feed_dict['output'][2]['output'], feed_dict['output'][2]['output_raw'] = fully_connected(feed_dict['output'][1]['output'], weights = feed_dict['output'][2]['weights'], nodes = layers[2]['nodes'], activation = layers[2]['activation'])\n",
    "            \n",
    "            #cost calculation\n",
    "            cost_per_epoch = cost_per_epoch - np.log(feed_dict['output'][2]['output'][np.argmax(feed_dict['train_label'][i + batch * batch_size])])\n",
    "            \n",
    "            #calculating the gradients\n",
    "            feed_dict['output'][2]['semi_update'] = feed_dict['output'][2]['output'] - feed_dict['train_label'][i + batch * batch_size].reshape(-1,1)\n",
    "            feed_dict['output'][2]['update'] = np.matmul(feed_dict['output'][2]['semi_update'] , np.transpose(np.vstack((feed_dict['output'][1]['output'],1))))\n",
    "            \n",
    "            temp = feed_dict['output'][2]['weights'][:,0:feed_dict['output'][2]['weights'].shape[1]-1]\n",
    "            feed_dict['output'][1]['semi_update'] = np.matmul(np.transpose(temp), feed_dict['output'][2]['semi_update']) * deriv(feed_dict['output'][1]['output_raw'])\n",
    "            feed_dict['output'][1]['update'] = np.matmul(feed_dict['output'][1]['semi_update'] , np.transpose(np.vstack((feed_dict['output'][0]['output'],1))))\n",
    "            \n",
    "            temp = feed_dict['output'][1]['weights'][:,0:feed_dict['output'][1]['weights'].shape[1]-1]\n",
    "            feed_dict['output'][0]['semi_update'] = np.matmul(np.transpose(temp), feed_dict['output'][1]['semi_update']) * deriv(feed_dict['output'][0]['output_raw'])\n",
    "            feed_dict['output'][0]['update'] = np.matmul(feed_dict['output'][0]['semi_update'],np.transpose(np.vstack((np.expand_dims(feed_dict['train_input'][i + batch * batch_size],axis = 1),1))))\n",
    "            \n",
    "            weights_fc_0 += feed_dict['output'][0]['update']\n",
    "            weights_fc_1 += feed_dict['output'][1]['update']\n",
    "            weights_fc_2 += feed_dict['output'][2]['update']\n",
    "            \n",
    "        #updating the gradient after each batch\n",
    "        feed_dict['vel'][0] = (feed_dict['learning_rate_alpha']**2) *feed_dict['vel'][0] - (feed_dict['learning_rate_alpha']+1)*feed_dict['learning_rate_epsilon'] * weights_fc_0\n",
    "        feed_dict['vel'][1] = (feed_dict['learning_rate_alpha']**2) *feed_dict['vel'][1] - (feed_dict['learning_rate_alpha']+1)*feed_dict['learning_rate_epsilon'] * weights_fc_1\n",
    "        feed_dict['vel'][2] = (feed_dict['learning_rate_alpha']**2) *feed_dict['vel'][2] - (feed_dict['learning_rate_alpha']+1)*feed_dict['learning_rate_epsilon'] * weights_fc_2 \n",
    "        feed_dict['output'][0]['weights'] += feed_dict['vel'][0]\n",
    "        feed_dict['output'][1]['weights'] += feed_dict['vel'][1]\n",
    "        feed_dict['output'][2]['weights'] += feed_dict['vel'][2]\n",
    "        \n",
    "    #printing the Average Loss after each epoch\n",
    "    if((epoch+1)%50 == 0):\n",
    "        print(\"Epoch: \" + str(epoch+1) + \" Loss: \" + str(cost_per_epoch/no_samples))\n",
    "    train_losses.append(cost_per_epoch/no_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"nestrov_momentum.npy\", feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = np.array(train_losses)\n",
    "plt.plot(train_losses)\n",
    "plt.title('LOSS Vs Epochs')\n",
    "plt.ylabel('Cross Entrphoy Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of softmax for one sample:\n",
      "[[9.99788800e-01]\n",
      " [2.11193203e-04]\n",
      " [6.46492176e-09]]\n",
      "\n",
      "Ground Truth of the same sample above:\n",
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "feed_dict['output'][0]['output'], feed_dict['output'][0]['output_raw'] = fully_connected(feed_dict['train_input'][0], weights = feed_dict['output'][0]['weights'], nodes = layers[0]['nodes'], activation = layers[0]['activation'])\n",
    "feed_dict['output'][1]['output'], feed_dict['output'][1]['output_raw'] = fully_connected(feed_dict['output'][0]['output'], weights = feed_dict['output'][1]['weights'], nodes = layers[1]['nodes'], activation = layers[1]['activation'])\n",
    "feed_dict['output'][2]['output'], feed_dict['output'][2]['output_raw'] = fully_connected(feed_dict['output'][1]['output'], weights = feed_dict['output'][2]['weights'], nodes = layers[2]['nodes'], activation = layers[2]['activation'])\n",
    "\n",
    "print 'output of softmax for one sample:'\n",
    "print feed_dict['output'][2]['output']\n",
    "\n",
    "print '\\nGround Truth of the same sample above:'\n",
    "print feed_dict['train_label'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = []\n",
    "gt = []\n",
    "# print(np.argmax(out))\n",
    "for i in range(feed_dict['test_input'].shape[0]):\n",
    "    feed_dict['output'][0]['output'], feed_dict['output'][0]['output_raw'] = fully_connected(feed_dict['test_input'][i], weights = feed_dict['output'][0]['weights'], nodes = layers[0]['nodes'], activation = layers[0]['activation'])\n",
    "    feed_dict['output'][1]['output'], feed_dict['output'][1]['output_raw'] = fully_connected(feed_dict['output'][0]['output'], weights = feed_dict['output'][1]['weights'], nodes = layers[1]['nodes'], activation = layers[1]['activation'])\n",
    "    feed_dict['output'][2]['output'], feed_dict['output'][2]['output_raw'] = fully_connected(feed_dict['output'][1]['output'], weights = feed_dict['output'][2]['weights'], nodes = layers[2]['nodes'], activation = layers[2]['activation'])\n",
    "    \n",
    "    test_predicted.append(np.argmax(feed_dict['output'][2]['output']))\n",
    "    gt.append(np.argmax(feed_dict['test_label'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs and the respective Groucd Truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 2, 2, 1, 0, 2, 2, 2, 2, 2, 0, 2, 1, 1, 2, 1, 2, 0, 0, 0, 2, 0, 0, 1, 0, 2, 2, 0, 1, 0]\n",
      "Actual   :  [0, 2, 2, 1, 0, 1, 2, 2, 2, 2, 0, 2, 1, 1, 2, 1, 2, 0, 0, 0, 2, 0, 0, 1, 0, 2, 2, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print 'predicted: ',test_predicted\n",
    "print 'Actual   : ', gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.966666666667\n"
     ]
    }
   ],
   "source": [
    "a = np.array(test_predicted) - np.array(gt)\n",
    "test_accuracy = (len(a) - np.count_nonzero(a))/float(len(a))\n",
    "\n",
    "print 'accuracy: ', str(test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
