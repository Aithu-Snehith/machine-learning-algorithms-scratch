{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: Tensorflow tutorials(https://www.tensorflow.org/tutorials/sequences/text_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 26346 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open('huge_c.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'// SPDX-License-Identifier: GPL-2.0\\n#include \"audit.h\"\\n#include <linux/fsnotify_backend.h>\\n#include <'\n",
      "'linux/namei.h>\\n#include <linux/mount.h>\\n#include <linux/kthread.h>\\n#include <linux/refcount.h>\\n#inclu'\n",
      "'de <linux/slab.h>\\n\\nstruct audit_tree;\\nstruct audit_chunk;\\n\\nstruct audit_tree {\\n\\trefcount_t count;\\n\\tin'\n",
      "'t goner;\\n\\tstruct audit_chunk *root;\\n\\tstruct list_head chunks;\\n\\tstruct list_head rules;\\n\\tstruct list_h'\n",
      "'ead list;\\n\\tstruct list_head same_root;\\n\\tstruct rcu_head head;\\n\\tchar pathname[];\\n};\\n\\nstruct audit_chun'\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder = True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '// SPDX-License-Identifier: GPL-2.0\\n#include \"audit.h\"\\n#include <linux/fsnotify_backend.h>\\n#include '\n",
      "Target data: '/ SPDX-License-Identifier: GPL-2.0\\n#include \"audit.h\"\\n#include <linux/fsnotify_backend.h>\\n#include <'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 16 ('/')\n",
      "  expected output: 16 ('/')\n",
      "Step    1\n",
      "  input: 16 ('/')\n",
      "  expected output: 2 (' ')\n",
      "Step    2\n",
      "  input: 2 (' ')\n",
      "  expected output: 44 ('S')\n",
      "Step    3\n",
      "  input: 44 ('S')\n",
      "  expected output: 42 ('P')\n",
      "Step    4\n",
      "  input: 42 ('P')\n",
      "  expected output: 31 ('D')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           21760     \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 85)            87125     \n",
      "=================================================================\n",
      "Total params: 4,047,189\n",
      "Trainable params: 4,047,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(len(vocab), embedding_dim,\n",
    "                              batch_input_shape=[BATCH_SIZE, None]))\n",
    "model.add(tf.keras.layers.CuDNNGRU(rnn_units,\n",
    "        return_sequences=True,\n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True))\n",
    "model.add(tf.keras.layers.Dense(len(vocab)))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 85) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_c_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.3378\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8581\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.1511\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.9667\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.7485\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.4750\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.2431\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.1185\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.9910\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.8767\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.7564\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.6457\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.5471\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.4573\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.3721\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 2.3039\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 2.2458\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.1756\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.1192\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.0716\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.0133\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.9690\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.9184\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.8763\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.8223\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.7843\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.7385\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.6874\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.6541\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.6110\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.5687\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.5273\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.4916\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.4454\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.4110\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.3637\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.3343\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2990\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.2538\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.2152\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.1831\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 1.1496\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.1099\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.0789\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.0504\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.0235\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.9998\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.9671\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.9359\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.9012\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.8713\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.8433\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.8219\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.7875\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7647\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7443\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7218\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.6971\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.6648\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.6509\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.6324\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.6025\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.5859\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5635\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5442\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5253\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.5089\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.4913\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.4726\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4592\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4384\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.4293\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.4130\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.3982\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3871\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.3687\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.3594\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.3493\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.3354\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.3205\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.3112\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.3031\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.2934\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.2834\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.2800\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.2692\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2660\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.2587\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.2529\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.2494\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.2412\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.2349\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.2277\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.2214\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.2210\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.2151\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.2070\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2010\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.2003\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.1922\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1923\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1872\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1887\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.1793\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.1827\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1805\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.1704\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1700\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1684\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1676\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.1638\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.1627\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.1583\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.1559\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1561\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1520\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.1448\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1478\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.1476\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.1414\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1400\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.1429\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.1394\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.1408\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.1347\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1337\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.1356\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1310\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.1308\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.1294\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.1249\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.1231\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.1212\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.1234\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.1214\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1188\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.1201\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.1228\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1193\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.1152\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1159\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.1115\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1116\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.1145\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1091\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.1077\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.1086\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.1121\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.1100\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1073\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.1073\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.1032\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1084\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1042\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.1023\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.1033\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1025\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0998\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1020\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.0996\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.0977\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.0980\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0944\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0959\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.0912\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0938\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0942\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.0944\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0870\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0945\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0950\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.0887\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0985\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0939\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.0947\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.0907\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0899\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0904\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0863\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.0871\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0892\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0893\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.0816\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0840\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0895\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.0825\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0812\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0820\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0829\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0865\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0846\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.0784\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0834\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0825\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0820\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0820\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0789\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0789\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0798\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0787\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=200\n",
    "\n",
    "# history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])\n",
    "\n",
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss Vs Epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, None, 256)            21760     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 85)             87125     \n",
      "=================================================================\n",
      "Total params: 4,047,189\n",
      "Trainable params: 4,047,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './training_checkpoints/ckpt_c_200'\n",
    "# tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(len(vocab), embedding_dim,\n",
    "                              batch_input_shape=[1, None]))\n",
    "model.add(tf.keras.layers.CuDNNGRU(rnn_units,\n",
    "        return_sequences=True,\n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True))\n",
    "model.add(tf.keras.layers.Dense(len(vocab)))\n",
    "\n",
    "model.load_weights(checkpoint_dir)\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a multinomial distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct audit_tree *tree)\n",
      "{\n",
      "\tput_tree *tree)\n",
      "{\n",
      "\treturn tree->pathname, 0, &path);\n",
      "\tif (IS_ERR(mark))\n",
      "\t\treturn;\n",
      "\tout_mutex:\n",
      "\tmutex_unlock(&audit_tree_group->mark_mutex);\n",
      "\t\treturn -ENOMEM;\n",
      "\t}\n",
      "\n",
      "\tmark = ale;\n",
      "\t\tfsnotify_free_mark(mark);\n",
      "\t\tfsnotify_put_mark(mark);\n",
      "\t\tkfree(chunk);\n",
      "\t\treturn 0;\n",
      "\t}\n",
      "\treplace_mark_chunk(old->mark, new);\n",
      "\t/*\n",
      "\t /      struct audit_chunk *chunk)\n",
      "{\n",
      "\tstruct audit_chunk *old;\n",
      "\n",
      "\tassert_spin_locted->chunks, list) {\n",
      "\t\t\tlist_move(&owner->list, &prune_list);\n",
      "\t\t\tneed_prune = 1;\n",
      "\t\t} else {\n",
      "\t\tstruct path path1, path2;\n",
      "\tstruct vfsmount *tagged;\n",
      "\tint err;\n",
      "\n",
      "\terr = kern_path(new, 0, &path2);\n",
      "\t\tif (!err) {\n",
      "\t\t\tgood_one = canlic inline struct audit_tree_mark *audit_mark(struct fsnotify_mark *mark,\n",
      "\t\t\t\t   err)\n",
      "\t\t\tgoto skip_it;\n",
      "\n",
      "\t\troot_mnt = collect_mounts(&path);\n",
      "\t\tpath_put(&path);\n",
      "\t\tif (IS_ERR(rootagner) /* reorder */\n",
      "\tfor (p = tree->chunks.next; p != &tree->chunks; p = q) {\n",
      "\t\tstruct node *node = list_entry(prune_list.next,\n",
      "\t\t\t\t\tstruct audit_chunk *chunk = from_chunk(mark) != chunk)\n",
      "\t\tgoto o\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"struct\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
