{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 2072753 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open('data.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<music21.note.Note B->\\n<music21.chord.Chord D4 F3 B-3>\\n<music21.chord.Chord D5 F5 B-5 D6>\\n<music21.ch'\n",
      "'ord.Chord F3 D4 B-3>\\n<music21.chord.Chord F5 B-5 D5 D6>\\n<music21.chord.Chord D4 B-3 F3>\\n<music21.chor'\n",
      "'d.Chord D5 E-6 F5 B-5>\\n<music21.chord.Chord D4 B-3 F3>\\n<music21.chord.Chord D6 D5 B-5 F5>\\n<music21.ch'\n",
      "'ord.Chord B-3 D4 F3>\\n<music21.chord.Chord F5 D5 B-5 D6>\\n<music21.chord.Chord D4 F3 B-3>\\n<music21.chor'\n",
      "'d.Chord D5 B-4 F5 B-5>\\n<music21.chord.Chord F3 D3 B-3>\\n<music21.note.Note B->\\n<music21.chord.Chord B-'\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder = True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '<music21.note.Note B->\\n<music21.chord.Chord D4 F3 B-3>\\n<music21.chord.Chord D5 F5 B-5 D6>\\n<music21.c'\n",
      "Target data: 'music21.note.Note B->\\n<music21.chord.Chord D4 F3 B-3>\\n<music21.chord.Chord D5 F5 B-5 D6>\\n<music21.ch'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 12 ('<')\n",
      "  expected output: 27 ('m')\n",
      "Step    1\n",
      "  input: 27 ('m')\n",
      "  expected output: 33 ('u')\n",
      "Step    2\n",
      "  input: 33 ('u')\n",
      "  expected output: 31 ('s')\n",
      "Step    3\n",
      "  input: 31 ('s')\n",
      "  expected output: 26 ('i')\n",
      "Step    4\n",
      "  input: 26 ('i')\n",
      "  expected output: 22 ('c')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 100), (256, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (256, None, 256)          8704      \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (256, None, 1024)         3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (256, None, 34)           34850     \n",
      "=================================================================\n",
      "Total params: 3,981,858\n",
      "Trainable params: 3,981,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(len(vocab), embedding_dim,\n",
    "                              batch_input_shape=[BATCH_SIZE, None]))\n",
    "model.add(tf.keras.layers.CuDNNGRU(rnn_units,\n",
    "        return_sequences=True,\n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True))\n",
    "model.add(tf.keras.layers.Dense(len(vocab)))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 100, 34) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_music_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_c_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 14s 170ms/step - loss: 1.3489\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 14s 171ms/step - loss: 0.2433\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 14s 170ms/step - loss: 0.2139\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 14s 171ms/step - loss: 0.2028\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 14s 173ms/step - loss: 0.1971\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 14s 172ms/step - loss: 0.1928\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 14s 172ms/step - loss: 0.1905\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 14s 174ms/step - loss: 0.1889\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 14s 175ms/step - loss: 0.1872\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 14s 175ms/step - loss: 0.1860\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "\n",
    "# history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])\n",
    "\n",
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss Vs Epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, None, 256)            8704      \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 34)             34850     \n",
      "=================================================================\n",
      "Total params: 3,981,858\n",
      "Trainable params: 3,981,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './training_music_checkpoints/ckpt_c_10'\n",
    "# tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(len(vocab), embedding_dim,\n",
    "                              batch_input_shape=[1, None]))\n",
    "model.add(tf.keras.layers.CuDNNGRU(rnn_units,\n",
    "        return_sequences=True,\n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True))\n",
    "model.add(tf.keras.layers.Dense(len(vocab)))\n",
    "\n",
    "model.load_weights(checkpoint_dir)\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 5000\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a multinomial distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen.txt', 'w') as f:\n",
    "    f.write(generate_text(model, start_string=u\"<\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
